---
author: "Pawe≈Ç Pechta"
title: "Multinomial LR Model for predicting the outcomes of football matches"
purpose: "This script presents  process of building and using Machine Learning model to predict football matches outcomes" 
---

```{r}
install.packages("tidyverse")
install.packages("mice")
install.packages("caTools")
install.packages("corrplot")
```


# Source data import to create dataset

```{r}
# package dependencies
library(tidyverse)

dataset <- dir("data", full.names = T) %>% map_df(read_csv)
# Import csv about 2011/2012 - 2021/2022 seasons from data catalog
# dir() returns a character vector of file names within source_data directory
# map_df() row-bind each element of output together
# read_csv() function as map_df parameter used to read data from csv file
```


# Processing and Exploring Data (limiting number of variables and removing NA)

```{r}
dataset <- dataset[c(2:10, 12:23)] # Removing unused variables by indexes
# What means delete of qualitative variables and statistics about betting
# and keeping only match statistics in dataset
```

```{r}
# Start of cleansing dataset

# package dependencies
library(mice)

md.pattern(dataset) # Checking for missing values in dataset
dataset <- na.omit(dataset) # Removing 1 full-empty row
```

```{r}
summary(dataset) # Display summary of dataset after cleansing procedure


write.csv(dataset, "./dataset.csv", row.names=FALSE) # Export dataframe to csv
# write_csv() function to save values to CSV file in repository
# row.names argument as FALSE
```


# Input Data preparation (removing multicollinear variables)

```{r}
# Preparing data to Correlation Matrix creating

str(dataset) # Display structure of dataset

df_corr <- dataset[,sapply(dataset, is.numeric)] # Keeping only num variables 

df_corr.cor = cor(df_corr, method = c("pearson")) # Creating Correlation Matrix

# package dependencies
library(corrplot)

palette = colorRampPalette(c("green", "white", "red")) (20)
heatmap(x = df_corr.cor, col = palette, symm = TRUE) # Visualizing the matrix
# heatmap(), df_corr.cor source matrix
```

```{r}
df_corr <- df_corr[c(7:16)] # Removing multicollinear variables

df_corr.cor = cor(df_corr, method = c("pearson")) 

heatmap(x = df_corr.cor, col = palette, symm = TRUE) # Compare matrix to base
```

```{r}
input_data <- dataset[c(1:3, 6, 9, 12:21)] 
# Keeping no-multicollinear independent variables in dataframe,restoring factors
```


# Splitting data into training and testing datasets to build and evaluate model

```{r}
# package dependencies
library(caTools)

# 70% of data for building LR model, 30% for evaluating it
set.seed(123)   #  Setting seed to ensure have same random numbers generated
sample = sample.split(input_data,SplitRatio = 0.70) # Splitting data 70:30 ratio
train = subset(input_data,sample == TRUE) # into training set
test = subset(input_data, sample == FALSE) # into test set

write.csv(train, "./training/training.csv", row.names = FALSE) # Export training 
write.csv(test, "./testing/test.csv", row.names = FALSE) # Export testing
```


# Building and Comparising Predictive Models (by AIC value)

```{r}
# defining reference level as "D" in accordance with the assumptions of LR
# you can choose freely any other level as reference
# (differences in the interpretation of the results)

train$FTR <- relevel(factor(train$FTR), ref = "D")
```

```{r}
# package dependencies
require(nnet)
```


```{r}
# Model with all variables (AIC value = 4525.707)

multinom.model_1 <- multinom(FTR ~HST + AST + HF + AF + HC + AC + HY + AY
                             + HR + AR +1, data = train)
summary(multinom.model_1)  # use it to see coefficients and standard errors etc.

summary <- summary(multinom.model_1)$coefficients/summary(multinom.model_1)$standard.errors
p <- (1 - pnorm(abs(summary), 0, 1)) * 2
head(p) # p-values

```

```{r}
# Model with only relevant variables

multinom.model_2 <- multinom(FTR ~AST + HST + AF + HC + AC + HY + HR + AR +1,
                             data = train)
summary(multinom.model_2)

# Model with only relevant variables has lower AIC value so should be better

summary <- summary(multinom.model_2)$coefficients/summary(multinom.model_2)$standard.errors
p <- (1 - pnorm(abs(summary), 0, 1)) * 2
head(p) # p-values

# 'HR' variables are relevant only for 'A' category of dependent variable,
# so can either be left or deleted from the model
```

```{r}
exp(coef(multinom.model_2)) # odds ratio
# model interpretations available in ./training/details.md
```

```{r}
multinom.model <- multinom.model_2 # rename model
```

```{r}
# Predicting on Test Data

output <- test

# Prediction using our model and save as "Predicted" variable
# predict() function: a factor of classifications based on H/A/D levels

output$Predicted <- predict(multinom.model, newdata = output, "class")
output <- output[c(1:4, 16)]
names(output)[4] <- "Actual" # rename variable "Full Time Result" to "Actual"

write.csv(output, "./test/output.csv", row.names = FALSE) # save as csv file
```

```{r}
# Evaluating the Model

# Building Confusion Matrix

install.packages('e1071', dependencies = TRUE)

observations <- factor(output$Actual,
                        levels = c("H", "A", "D"))

predicted <- factor(output$Predicted,
                       levels = c("H", "A", "D"))

conf <- table(predicted, observations)


library(caret) 
f.conf <- confusionMatrix(conf)

# package dependencies

install.packages('yardstick')
library(yardstick)
library(ggplot2)

# Size of sample is equal to dataset size

set.seed(123)
mat_conf <- data.frame(
  FTR = sample(0:1,1325, replace = T),
  predicted = sample(0:1,1325, replace = T)
)
mat_conf$FTR <- observations
mat_conf$predicted <- predicted

cm <- conf_mat(mat_conf, FTR, predicted)

# Confusion matrix  to assess the quality of classification on a test set
# Visualize confusion matrix

autoplot(cm, type = "heatmap") +
  scale_fill_gradient(low = "firebrick1", high = "aquamarine1")

print(f.conf)

# assessment of the quality of prediction available in ./test/evaluation.md
```


```{r}

# Future matches prediction (an example of the practical use of the model)

library("readxl")
average_stats <- read_excel("./future_matches_prediction/average_stats.xlsx")

predictions <- average_stats
predictions$Prediction <- predict(multinom.model, newdata = predictions,
                                  "class")
predictions <- predictions[c(1:4, 13)]
write.csv(predictions, "./future_matches_prediction/predictions.csv", row.names = FALSE)

# more details in "future_matches_prediction" catalog

```

